{
  "table_id": "tbl-0002-00-bd2478",
  "pdf_path": "data\\transformer_article.pdf",
  "page": 2,
  "bbox": [
    107.641,
    72.50643679999996,
    505.743154821,
    722.1519216
  ],
  "title": null,
  "headers": [
    "1 Introduction"
  ],
  "rows": [
    [
      ""
    ],
    [
      "Recurrentneuralnetworks,longshort-termmemory[13]andgatedrecurrent[7]neuralnetworks"
    ],
    [
      "inparticular,havebeenfirmlyestablishedasstateoftheartapproachesinsequencemodelingand"
    ],
    [
      "transductionproblemssuchaslanguagemodelingandmachinetranslation[35,2,5]. Numerous"
    ],
    [
      "effortshavesincecontinuedtopushtheboundariesofrecurrentlanguagemodelsandencoder-decoder"
    ],
    [
      "architectures[38,24,15]."
    ],
    [
      ""
    ],
    [
      "Recurrentmodelstypicallyfactorcomputationalongthesymbolpositionsoftheinputandoutput"
    ],
    [
      "sequences. Aligningthepositionstostepsincomputationtime,theygenerateasequenceofhidden"
    ],
    [
      ""
    ]
  ],
  "row_count": 63,
  "csv_path": "artifacts_pdf\\tables\\transformer_article\\tbl-0002-00-bd2478.csv",
  "json_path": "artifacts_pdf\\tables\\transformer_article\\tbl-0002-00-bd2478.json",
  "preview_text": "Table. Headers: 1 Introduction. Example rows:  ; Recurrentneuralnetworks,longshort-termmemory[13]andgatedrecurrent[7]neuralnetworks"
}