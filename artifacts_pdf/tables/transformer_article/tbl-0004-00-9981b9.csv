Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several
attentionlayersrunninginparallel.
""
"ofthevalues,wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionofthe"
querywiththecorrespondingkey.
""
3.2.1 ScaledDot-ProductAttention
""
"Wecallourparticularattention""ScaledDot-ProductAttention""(Figure2). Theinputconsistsof"
""
"queriesandkeysofdimensiond ,a√ndvaluesofdimensiond . Wecomputethedotproductsofthe
k v"
"querywithallkeys,divideeachby d ,andapplyasoftmaxfunctiontoobtaintheweightsonthe
k"
values.
""
"Inpractice,wecomputetheattentionfunctiononasetofqueriessimultaneously,packedtogether"
intoamatrixQ. ThekeysandvaluesarealsopackedtogetherintomatricesK andV. Wecompute
thematrixofoutputsas:
""
QKT
""
"Attention(Q,K,V)=softmax( √ )V (1)"
"d
k"
""
"Thetwomostcommonlyusedattentionfunctionsareadditiveattention[2],anddot-product(multi-"
"plicative)attention. Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactor"
of √1 . Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwith
dk
"asinglehiddenlayer. Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionis"
"muchfasterandmorespace-efficientinpractice,sinceitcanbeimplementedusinghighlyoptimized"
matrixmultiplicationcode.
""
""
"Whileforsmallvaluesofd thetwomechanismsperformsimilarly,additiveattentionoutperforms
k"
""
"dotproductattentionwithoutscalingforlargervaluesofd [3]. Wesuspectthatforlargevaluesof
k"
""
"d ,thedotproductsgrowlargeinmagnitude,pushingthesoftmaxfunctionintoregionswhereithas
k"
"extremelysmallgradients4. Tocounteractthiseffect,wescalethedotproductsby √1 ."
d
k
""
3.2.2 Multi-HeadAttention
""
""
"Insteadofperformingasingleattentionfunctionwithd -dimensionalkeys,valuesandqueries,
model"
"wefounditbeneficialtolinearlyprojectthequeries,keysandvalueshtimeswithdifferent,learned"
""
"linearprojectionstod ,d andd dimensions,respectively. Oneachoftheseprojectedversionsof
k k v"
""
"queries,keysandvalueswethenperformtheattentionfunctioninparallel,yieldingd -dimensional
v"
""
"4Toillustratewhythedotproductsgetlarge,assumethatthecomponentsofqandkareindependentrandom"
"(cid:80)dk
variableswithmean0andvariance1.Thentheirdotproduct,q·k= q k ,hasmean0andvarianced ."
i=1 i i k
